{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('newData/IC_2004.csv')\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswahl der nummerischen Spalten aus den Dataframe\n",
    "\n",
    "Zudem wollen wir die `X` und `y` Werte festlegen, die wir für unser Modell benötigen.\n",
    "\n",
    "**Daten**: `bhf_cat`, `dayname_cat`, `trainno_cat`, `feiertag_cat`, `ferien_cat` und `zeit`\n",
    "\n",
    "**Vorherzusage**: `isadelay`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = df[['bhf_cat', 'dayname_cat', 'trainno_cat', 'zeit', 'temperature_c', 'air_pressure_hpa','relative_humidity', 'dew_point_c', 'wind_speed_kmh', 'time_since_last_station', 'time_since_first_station', 'stay_time', 'track_length' ,'track_length_since_start' , 'weather_condition_cat']]\n",
    "X = df[['track_length_since_start', 'time_since_first_station', 'station_number', 'lat', 'lon', 'track_length', 'zeit']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['isadelay5']\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswahl des Klassifikators\n",
    "\n",
    "Anhand der nachfolgenden Graphik wählen wir den Klassifikator.\n",
    "\n",
    "![Sklearn Mindmap](https://scikit-learn.org/stable/_static/ml_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "#### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train a dummy classifier to make predictions based on the most_frequent class value\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_classifier = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_classifier.fit( X_train,y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dummy_classifier = dummy_classifier.predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0],(y_test != y_dummy_classifier).sum()))\n",
    "confusion_matrix(y_test, y_dummy_classifier, labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "gnb = GaussianNB()\n",
    "model_nb = gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auswertung\n",
    "Durchgang 1: `Number of mislabeled points out of a total 9865 points : 2693` =  **27**% Falsch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb = model_nb.predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0],(y_test != y_pred_nb).sum()))\n",
    "confusion_matrix(y_test, y_pred_nb, labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machinen\n",
    "\n",
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model_svm = svm.SVC(gamma='scale')\n",
    "model_svm.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auswertung\n",
    "Durchgang 1: `Number of mislabeled points out of a total 9865 points : 2715` = **27,5**% Falsch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm = model_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0],(y_test != y_pred_svm).sum()))\n",
    "confusion_matrix(y_test, y_pred_svm, labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entscheidungsbaum\n",
    "#### Training\n",
    "\n",
    "Number of mislabeled points out of a total 9865 points : 2682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "model_dt = tree.DecisionTreeClassifier()\n",
    "model_dt = model_dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt = model_dt.predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0],(y_test != y_pred_dt).sum()))\n",
    "confusion_matrix(y_test, y_pred_dt, labels=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tree.plot_tree(model_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mit Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.mean(), X_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_sc = scaler.transform(X_train)\n",
    "X_test_sc = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc.mean(), X_train_sc.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes mit Scaling\n",
    "Number of mislabeled points out of a total 9865 points : 2693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb_sc = GaussianNB()\n",
    "model_nb_sc = gnb_sc.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nb_sc = model_nb_sc.predict(X_test_sc)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test_sc.shape[0],(y_test != y_pred_nb_sc).sum()))\n",
    "confusion_matrix(y_test, y_pred_nb_sc, labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM mit Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "model_svm_sc = svm.SVC(gamma='scale')\n",
    "model_svm_sc.fit(X_train_sc, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_svm_sc = model_svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test_sc.shape[0],(y_test != y_pred_svm_sc).sum()))\n",
    "confusion_matrix(y_test, y_pred_svm_sc, labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entscheidungsbaum mit Scaling\n",
    "#### Training\n",
    "\n",
    "Number of mislabeled points out of a total 9865 points : 2685"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dt_sc = tree.DecisionTreeClassifier()\n",
    "model_dt_sc = model_dt_sc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_dt_sc = model_dt_sc.predict(X_test)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test.shape[0],(y_test != y_pred_dt_sc).sum()))\n",
    "confusion_matrix(y_test, y_pred_dt_sc, labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nearest Neighbor mit Scaling\n",
    "Number of mislabeled points out of a total 9865 points : 4318"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "model_nnc_sc = NearestCentroid()\n",
    "model_nnc_sc.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nnc_sc = model_nnc_sc.predict(X_test_sc)\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test_sc.shape[0],(y_test != y_pred_nnc_sc).sum()))\n",
    "confusion_matrix(y_test, y_pred_nnc_sc, labels=[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuronale Netze mit Keras und Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "model_nn = Sequential()\n",
    "\n",
    "model_nn.add(Dense(units=12, activation='relu', kernel_regularizer=l2(0.01), input_dim=6))\n",
    "model_nn.add(Dense(units=6, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_nn.add(Dense(units=6, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model_nn.add(Dense(units=1, activation='sigmoid', kernel_regularizer=l2(0.01)))\n",
    "\n",
    "adam = Adam(lr=0.01, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0001, amsgrad=False)\n",
    "\n",
    "model_nn.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_nn.fit(X_train, y_train, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_and_metrics = model_nn.evaluate(X_test, y_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn = model_nn.predict(X_test, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_nn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, y_pred_nn > 0.5, labels=[0,1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
