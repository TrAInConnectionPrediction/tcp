{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connections(origin, destination, dt=datetime.now(), only_direct=False):\n",
    "        \"\"\"\n",
    "        Find connections between two stations\n",
    "        Args:\n",
    "            origin (str): origin station\n",
    "            destination (str): destination station\n",
    "            dt (datetime): date and time for query\n",
    "            only_direct (bool): only direct connections\n",
    "        \"\"\"\n",
    "        query = {\n",
    "            'S': origin,\n",
    "            'Z': destination,\n",
    "            'date': dt.strftime(\"%d.%m.%y\"),\n",
    "            'time': dt.strftime(\"%H:%M\"),\n",
    "            'start': 1,\n",
    "            'REQ0JourneyProduct_opt0': 1 if only_direct else 0\n",
    "        }\n",
    "        rsp = requests.get('http://mobile.bahn.de/bin/mobil/query.exe/dox?', params=query)\n",
    "        print(rsp.url)\n",
    "        return parse_connections(rsp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_connections(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    connections = list()\n",
    "\n",
    "    for row in soup.find_all(\"td\", class_=\"overview timelink\"):\n",
    "        columns = row.parent.find_all(\"td\")\n",
    "\n",
    "        try:\n",
    "            price_raw = columns[3].find(\"span\", class_=\"bold\").text.strip().replace(',', '.')\n",
    "            price = float(price_raw)\n",
    "        except:\n",
    "            price = None\n",
    "        data = {\n",
    "            'details': columns[0].a.get('href').replace('!details=opened!', '!details=opened!detailsVerbund=opened!'),\n",
    "            'departure': columns[0].a.contents[0].string,\n",
    "            'arrival': columns[0].a.contents[2].string,\n",
    "            'transfers': int(columns[2].contents[0]),\n",
    "            'time': columns[2].contents[2],\n",
    "            'products': columns[3].contents[0].split(', '),\n",
    "            'price': price,\n",
    "        }\n",
    "        if int(columns[2].contents[0]) != 0:\n",
    "            data['trains'] = get_trains(data['details'].replace('&abroadage=1&', ''))\n",
    "        else:\n",
    "            data['trains'] = []\n",
    "        \n",
    "        connections.append(data)\n",
    "    return connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trains(url):\n",
    "    \n",
    "    rsp = requests.get(url)\n",
    "    soup = BeautifulSoup(rsp.text, \"html.parser\")\n",
    "    an, ab = {}, {}\n",
    "    connections, trains, date = [], [] ,[]\n",
    "    #get start\n",
    "    for row in soup.find_all(\"div\", class_=\"rline haupt routeStart\"):\n",
    "        erg = str(row).replace('<', '\\n').replace('>', '\\n').split('\\n')\n",
    "        #print(erg)\n",
    "        start['bhf'] = erg[5]\n",
    "        if len(erg[10].split(' ')) <= 5:\n",
    "            start['platform'] = erg[10].split(' ') \n",
    "        else:\n",
    "            erg[10] = erg[10].split(' ') #weird edge cases 'fern'\n",
    "            print('Edge case:', erg[10])\n",
    "            erg[10].pop(4)\n",
    "            start['platform'] = erg[10]\n",
    "    #get end\n",
    "    for row in soup.find_all(\"div\", class_=\"rline haupt routeEnd routeEnd__IV\"):\n",
    "        erg = str(row).replace('<', '\\n').replace('>', '\\n').split('\\n')\n",
    "        #print(erg)\n",
    "        end['bhf'] = erg[9]\n",
    "        if len(erg[3].split(' ')) <= 5:\n",
    "            end['platform'] = erg[3].split(' ') \n",
    "        else:\n",
    "            erg[3] = erg[3].split(' ') #weird edge cases 'fern'\n",
    "            print('Edge case:', erg[3])\n",
    "            erg[3].pop(4)\n",
    "            end['platform'] = erg[3]\n",
    "    #get trains\n",
    "    for row in soup.find_all(\"a\", class_=\"flaparrow\"):\n",
    "        train = str(row).split('\\n')\n",
    "        #check if this is the train line\n",
    "        if len(train) > 2:\n",
    "            #get train number into right format\n",
    "            train = train[2].split(' ')\n",
    "            trains.append(train[0] + '_' + train[-1])\n",
    "    #get anfahrts infos\n",
    "    for row in soup.find_all(\"div\", class_=\"rline haupt routeChange routeChange__IV\"):\n",
    "        erg = str(row).replace('<', '\\n').replace('>', '\\n').split('\\n')\n",
    "        if len(erg[3].split(' ')) <= 5:\n",
    "            an[erg[9]] = erg[3].split(' ') \n",
    "        else:\n",
    "            erg[3] = erg[3].split(' ') #weird edge cases 'fern'\n",
    "            print('Edge case:', erg[3])\n",
    "            erg[3].pop(4)\n",
    "            an[erg[9]] = erg[3]\n",
    "    #get abfahrts infos\n",
    "    for row in [*soup.find_all(\"div\", class_=\"rline haupt stationDark routeChange routeChangeIV\"),*soup.find_all(\"div\", class_=\"rline haupt routeChange routeChangeIV\")]:\n",
    "        erg = str(row).replace('<', '\\n').replace('>', '\\n').split('\\n')\n",
    "        if len(erg[10].split(' ')) <= 5:\n",
    "            ab[erg[5]] = erg[10].split(' ') \n",
    "        else:\n",
    "            erg[10] = erg[10].split(' ') #weird edge cases 'fern'\n",
    "            print('Edge case:',erg[10])\n",
    "            erg[10].pop(4)\n",
    "            ab[erg[5]] = erg[10]\n",
    "    #get date and time of connection\n",
    "    for row in soup.find_all(\"span\", class_=\"querysummary2\"):\n",
    "        erg = str(row).replace(',', '\\n').split('\\n')\n",
    "        if \"img\" in erg[1]:\n",
    "            erg.pop(1)\n",
    "        if 'span' in erg[4]:\n",
    "            erg.pop(4)\n",
    "        print(erg)\n",
    "        date.append(erg[3].replace(' ', ''))#first start time\n",
    "        date.append(erg[2])#start date\n",
    "        if len(erg) > 7:\n",
    "            date.append(erg[6]) #if the end date is diffenrent than the starts\n",
    "\n",
    "    if(len(ab) != len(an) != (len(trains)-1)): #check if there is an eqal amount of everything\n",
    "        print('ERROR')\n",
    "    #print(an)\n",
    "    #print(ab)\n",
    "    print(start)\n",
    "    print(end)\n",
    "    info = {\n",
    "                'startbhf': start['bhf'],\n",
    "                'endbhf': end['bhf'],\n",
    "                'starttrain': trains[0],\n",
    "                'startplatform': start['platform'][len(start['platform'])-1],\n",
    "                'endplatform': end['platform'][len(end['platform'])-1],\n",
    "                'starttime': datetime.strptime(start['platform'][1] + date[1], '%H:%M %d.%m.%y'),\n",
    "                'endtime': datetime.strptime(end['platform'][1] + date[1], '%H:%M %d.%m.%y') if len(date) == 2 else datetime.strptime(end['platform'][1] + date[2], '%H:%M %d.%m.%y')\n",
    "            }\n",
    "    connections.append(info)\n",
    "    for no in range(len(trains)-1):\n",
    "        try:\n",
    "            info = {\n",
    "                'anbhf': list(an.keys())[no],\n",
    "                'abbhf': list(ab.keys())[no],\n",
    "                'antrain': trains[no],\n",
    "                'abtrain': trains[no+1],\n",
    "                'transfertime': datetime.strptime(ab[list(ab.keys())[no]][1], '%H:%M') - datetime.strptime(an[list(an.keys())[no]][1], '%H:%M'),\n",
    "                'anplatform': an[list(an.keys())[no]][4] if len(an[list(an.keys())[no]]) == 5 else ab[list(ab.keys())[no]][4],# sometimes the platform is the same  \n",
    "                'abplatform': ab[list(ab.keys())[no]][4] if len(ab[list(ab.keys())[no]]) == 5 else an[list(an.keys())[no]][4],# sometimes the platform is the same \n",
    "            }\n",
    "            if len(date) > 2: #is the date today or tomorrow?\n",
    "                if datetime.strptime(date[0], '%H:%M') > datetime.strptime(an[list(an.keys())[no]][1], '%H:%M'):\n",
    "                    info['anzeit'] = datetime.strptime(an[list(an.keys())[no]][1] + date[2], '%H:%M %d.%m.%y')\n",
    "                else:\n",
    "                    info['anzeit'] = datetime.strptime(an[list(an.keys())[no]][1] + date[1], '%H:%M %d.%m.%y')\n",
    "                if datetime.strptime(date[0], '%H:%M') > datetime.strptime(ab[list(ab.keys())[no]][1], '%H:%M'):\n",
    "                    info['abzeit'] = datetime.strptime(ab[list(ab.keys())[no]][1] + date[2], '%H:%M %d.%m.%y')\n",
    "                else:\n",
    "                    info['abzeit'] = datetime.strptime(ab[list(ab.keys())[no]][1] + date[1], '%H:%M %d.%m.%y')\n",
    "            else:\n",
    "                info['anzeit'] = datetime.strptime(an[list(an.keys())[no]][1] + date[1], '%H:%M %d.%m.%y')\n",
    "                info['abzeit'] = datetime.strptime(ab[list(ab.keys())[no]][1] + date[1], '%H:%M %d.%m.%y')\n",
    "            connections.append(info)\n",
    "        except:\n",
    "            print('Looks like something is weird with that url: \\n %s' % url)\n",
    "            connections.append('')\n",
    "    return connections       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cons = connections('Tübingen HbF', 'Mannheim HbF', datetime.now() - timedelta(4))\n",
    "#datetime(2019, 9, 14, 17, 0)\n",
    "#['<span class=\"querysummary2\" id=\"dtlOpen_2\">', 'Do', ' 03.10.19', ' 17:30', '-', 'Fr', ' 04.10.19', '06:06', '</span>']\n",
    "#['<span class=\"querysummary2\" id=\"dtlOpen_2\">', 'Sa', ' 14.09.19', ' 17:15', '-', 'So', ' 15.09.19', '06:06', '</span>']\n",
    "cons = connections('Tübingen Hbf', 'Berlin HbF', datetime(2019, 9, 14, 17, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}